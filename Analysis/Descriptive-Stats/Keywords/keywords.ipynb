{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Analysis\n",
    "\n",
    "Tasks:\n",
    "- Find top words by media ideology through IDF scores (https://kavita-ganesan.com/python-keyword-extraction/#.YnUzEdrMJPY)\n",
    "- TFIDF scores (https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb)\n",
    "https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency weighed by the inverse document frequency) is a score that measures a word’s relevance in the entire corpus. Given a particular document, if we consider the word “the”, it is present several times so it has a high TF, but it is present also in almost every document, hence, IDF is very low. Overall, the word “the” has a low TF-IDF score. We suppose that the keywords of a document should have a high TF-IDF score as the higher the numerical weight value, the rarer the term. The reason we take the inverse, or flipped fraction, of document frequency is to boost the rarer words that occur in relatively few documents. By evaluating TF-IDF, we understand how important a word is to a document and to the entire corpus. When using tf-idf scores instead of raw word counts as features, stopwords should disappear automatically. The smaller the weight, the more common the term. \n",
    "\n",
    "tf-idf = term_frequency * inverse_document_frequency\n",
    "\n",
    "term_frequency = number of times a given term appears in document\n",
    "\n",
    "inverse_document_frequency = log(total number of documents / number of documents with term) + 1*****\n",
    "\n",
    "The process of using TF-IDF is:\n",
    "1. Clean data / Preprocessing — Clean data (standardise data), normalize data (all lower case), lemmatize data (all words to root words).\n",
    "2. Tokenize words with frequency\n",
    "3. Find TF for words\n",
    "4. Find IDF for words\n",
    "5. Vectorize vocabulary\n",
    "\n",
    "With our data we define:\n",
    "- document = news media story\n",
    "- corpus = entire collection of stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>maintext</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>media_name</th>\n",
       "      <th>ideology</th>\n",
       "      <th>Congress</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/02/13</td>\n",
       "      <td>Advertisement\\r\\r\\nIn honor of our 95 annivers...</td>\n",
       "      <td>6 Ways the League of Women Voters Has Impacted...</td>\n",
       "      <td>http://www.huffingtonpost.com/elisabeth-macnam...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>left</td>\n",
       "      <td>114th</td>\n",
       "      <td>honor anniversary list things americans part l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/02/10</td>\n",
       "      <td>As state legislatures shift into high gear, ma...</td>\n",
       "      <td>Opportunities for Effective Election Reforms C...</td>\n",
       "      <td>http://www.huffingtonpost.com/robert-m-brandon...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>left</td>\n",
       "      <td>114th</td>\n",
       "      <td>state legislatures shift high gear election re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/02/22</td>\n",
       "      <td>FILE - In a Tuesday, Nov. 4, 2014 file photo, ...</td>\n",
       "      <td>Scott Walker Pushes ALEC 'Right to Work' Bill,...</td>\n",
       "      <td>http://www.huffingtonpost.com/mary-bottari/sco...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>left</td>\n",
       "      <td>114th</td>\n",
       "      <td>file tuesday nov file photo wisconsin republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/02/25</td>\n",
       "      <td>Former Ohio Gov. Ted Strickland (D) announced ...</td>\n",
       "      <td>Ted Strickland Announces He's Running For The ...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/02/25/ted-s...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>left</td>\n",
       "      <td>114th</td>\n",
       "      <td>ohio gov ted strickland announced wednesday ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/02/26</td>\n",
       "      <td>Nevada Senate Minority Leader Michael Roberson...</td>\n",
       "      <td>Nevada GOP Pushes New Gun Law Reminiscent Of '...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/02/26/nevad...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>left</td>\n",
       "      <td>114th</td>\n",
       "      <td>nevada senate minority leader michael roberson...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                           maintext  \\\n",
       "0  2015/02/13  Advertisement\\r\\r\\nIn honor of our 95 annivers...   \n",
       "1  2015/02/10  As state legislatures shift into high gear, ma...   \n",
       "2  2015/02/22  FILE - In a Tuesday, Nov. 4, 2014 file photo, ...   \n",
       "3  2015/02/25  Former Ohio Gov. Ted Strickland (D) announced ...   \n",
       "4  2015/02/26  Nevada Senate Minority Leader Michael Roberson...   \n",
       "\n",
       "                                               title  \\\n",
       "0  6 Ways the League of Women Voters Has Impacted...   \n",
       "1  Opportunities for Effective Election Reforms C...   \n",
       "2  Scott Walker Pushes ALEC 'Right to Work' Bill,...   \n",
       "3  Ted Strickland Announces He's Running For The ...   \n",
       "4  Nevada GOP Pushes New Gun Law Reminiscent Of '...   \n",
       "\n",
       "                                              source       media_name  \\\n",
       "0  http://www.huffingtonpost.com/elisabeth-macnam...  Huffington Post   \n",
       "1  http://www.huffingtonpost.com/robert-m-brandon...  Huffington Post   \n",
       "2  http://www.huffingtonpost.com/mary-bottari/sco...  Huffington Post   \n",
       "3  http://www.huffingtonpost.com/2015/02/25/ted-s...  Huffington Post   \n",
       "4  http://www.huffingtonpost.com/2015/02/26/nevad...  Huffington Post   \n",
       "\n",
       "  ideology Congress                                               text  \n",
       "0     left    114th  honor anniversary list things americans part l...  \n",
       "1     left    114th  state legislatures shift high gear election re...  \n",
       "2     left    114th  file tuesday nov file photo wisconsin republic...  \n",
       "3     left    114th  ohio gov ted strickland announced wednesday ll...  \n",
       "4     left    114th  nevada senate minority leader michael roberson...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/analo/OneDrive - University of Glasgow/University of Glasgow/Amsterdam Visit/ASCoR-Project/Analysis/Descriptive-Stats/preprocessed.csv', encoding='latin-1')\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two different datasets for media split by ideology\n",
    "ideology = df.groupby(\"ideology\")\n",
    "left = ideology.get_group('left')\n",
    "right = ideology.get_group('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vocabulary\n",
    "While cv.fit(...) would only create the vocabulary, cv.fit_transform(...) creates the vocabulary and returns a term-document matrix which is what we want. With this, each column in the matrix represents a word in the vocabulary while each row represents the document in our dataset where the values in this case are the word counts. Note that with this representation, counts of some words could be 0 if the word did not appear in the corresponding document. We use countVectorizer to create a vocabulary and generate word counts.\n",
    "\n",
    "We ignore all words that have appeared in 95% of the documents, since those may be unimportant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = df['text'].apply(str) # all documents\n",
    "# text =left['text'].apply(str) # left leaning media\n",
    "text =right['text'].apply(str) # right leaning media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labor',\n",
       " 'giant',\n",
       " 'service',\n",
       " 'employees',\n",
       " 'international',\n",
       " 'union',\n",
       " 'soul',\n",
       " 'day',\n",
       " 'drive',\n",
       " 'hispanic',\n",
       " 'turnout',\n",
       " 'midterm',\n",
       " 'elections',\n",
       " 'distributing',\n",
       " 'language',\n",
       " 'public',\n",
       " 'tuesday',\n",
       " 'honor',\n",
       " 'dead',\n",
       " 'relatives']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore words that appear in 95% of documents and in less that 1% of documents,\n",
    "cv=CountVectorizer(max_df=0.95, min_df =0.01)\n",
    "word_count_vector= cv.fit_transform(text)\n",
    "list(cv.vocabulary_.keys())[:20] #10 words from our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the IDF\n",
    "We use TfidfTransformer to Compute Inverse Document Frequency (IDF). In the code below, we are essentially taking the sparse matrix from CountVectorizer (word_count_vector) to generate the IDF when you invoke tfidf_transformer.fit(...). Once we have our IDF computed, we are now ready to compute TF-IDF and then extract top keywords from the TF-IDF vectors. IDF values are sorted in descending order. The lower the IDF value of a word, the less unique it is to any particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector) # all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>voter</th>\n",
       "      <td>1.060078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.146021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>1.241533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>election</th>\n",
       "      <td>1.263298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voting</th>\n",
       "      <td>1.307508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>1.320278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>1.363781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>law</th>\n",
       "      <td>1.475500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voters</th>\n",
       "      <td>1.483033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laws</th>\n",
       "      <td>1.494440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_weights\n",
       "voter        1.060078\n",
       "id           1.146021\n",
       "state        1.241533\n",
       "election     1.263298\n",
       "voting       1.307508\n",
       "vote         1.320278\n",
       "people       1.363781\n",
       "law          1.475500\n",
       "voters       1.483033\n",
       "laws         1.494440"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values for whole corpus\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names_out(),columns=[\"idf_weights\"]) \n",
    "\n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing TF-IDF and Extracting Keywords of all articles\n",
    "Once we have our IDF computed, we are now ready to compute TF-IDF and extract the top keywords. In this example, we will extract top keywords for the articles. We will start by reading our test file, extracting the necessary fields (title and body) and get the texts into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles into a list\n",
    "docs_test=text.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(idx):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords):\n",
    "\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug 0.288\n",
      "indiana 0.262\n",
      "moore 0.235\n",
      "city 0.227\n",
      "nfl 0.22\n",
      "abuse 0.168\n",
      "coalition 0.14\n",
      "treatment 0.131\n",
      "margins 0.11\n",
      "users 0.105\n"
     ]
    }
   ],
   "source": [
    "idx=1 #article number\n",
    "keywords=get_keywords(idx)\n",
    "print_results(idx,keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labor giant service employees international un...</td>\n",
       "      <td>{'hispanic': 0.501, 'soul': 0.23, 'pew': 0.229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tribune star terre haute slim margins change v...</td>\n",
       "      <td>{'drug': 0.288, 'indiana': 0.262, 'moore': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raleigh ap year marked hundreds arrests nation...</td>\n",
       "      <td>{'moral': 0.279, 'raleigh': 0.24, 'saturday': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>austin texas federal appeals court struck texa...</td>\n",
       "      <td>{'appeals': 0.344, 'texas': 0.329, 'violates':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thursday ceremony commemorate anniversary voti...</td>\n",
       "      <td>{'folks': 0.418, 'turns': 0.31, 'obama': 0.205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>watching media rush defend president biden wei...</td>\n",
       "      <td>{'biden': 0.381, 'putin': 0.365, 'approval': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>year list hollywood actor smith blew iconic ca...</td>\n",
       "      <td>{'smith': 0.655, 'hollywood': 0.208, 'theory':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>listen fox news articles eyes world focus suff...</td>\n",
       "      <td>{'silence': 0.301, 'tech': 0.288, 'image': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>democratic congressman jamaal bowman york arre...</td>\n",
       "      <td>{'capitol': 0.47, 'police': 0.382, 'arrested':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>rep mondaire jones ally left squad thursday ca...</td>\n",
       "      <td>{'jones': 0.38, 'sinema': 0.353, 'manchin': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1714 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    doc  \\\n",
       "0     labor giant service employees international un...   \n",
       "1     tribune star terre haute slim margins change v...   \n",
       "2     raleigh ap year marked hundreds arrests nation...   \n",
       "3     austin texas federal appeals court struck texa...   \n",
       "4     thursday ceremony commemorate anniversary voti...   \n",
       "...                                                 ...   \n",
       "1709  watching media rush defend president biden wei...   \n",
       "1710  year list hollywood actor smith blew iconic ca...   \n",
       "1711  listen fox news articles eyes world focus suff...   \n",
       "1712  democratic congressman jamaal bowman york arre...   \n",
       "1713  rep mondaire jones ally left squad thursday ca...   \n",
       "\n",
       "                                               keywords  \n",
       "0     {'hispanic': 0.501, 'soul': 0.23, 'pew': 0.229...  \n",
       "1     {'drug': 0.288, 'indiana': 0.262, 'moore': 0.2...  \n",
       "2     {'moral': 0.279, 'raleigh': 0.24, 'saturday': ...  \n",
       "3     {'appeals': 0.344, 'texas': 0.329, 'violates':...  \n",
       "4     {'folks': 0.418, 'turns': 0.31, 'obama': 0.205...  \n",
       "...                                                 ...  \n",
       "1709  {'biden': 0.381, 'putin': 0.365, 'approval': 0...  \n",
       "1710  {'smith': 0.655, 'hollywood': 0.208, 'theory':...  \n",
       "1711  {'silence': 0.301, 'tech': 0.288, 'image': 0.2...  \n",
       "1712  {'capitol': 0.47, 'police': 0.382, 'arrested':...  \n",
       "1713  {'jones': 0.38, 'sinema': 0.353, 'manchin': 0....  \n",
       "\n",
       "[1714 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate tf-idf for all news articles. \n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform(docs_test))\n",
    "\n",
    "results=[]\n",
    "for i in range(tf_idf_vector.shape[0]):\n",
    "    \n",
    "    # get vector for a single document\n",
    "    curr_vector=tf_idf_vector[i]\n",
    "    \n",
    "    #sort the tf-idf vector by descending order of scores\n",
    "    sorted_items=sort_coo(curr_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    \n",
    "    results.append(keywords)\n",
    "\n",
    "# create dataframe with top keywords per article\n",
    "df_tfidf=pd.DataFrame(zip(docs_test,results),columns=['doc','keywords'])\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataset contains a dict for each keyword, I extracted these keywords and counted them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "listkey = df_tfidf['keywords'].to_list() # convert dict of keywords to list\n",
    "stringkey = str(listkey) # convert list to str\n",
    "\n",
    "def preprocess(raw_text):\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "    words = letters_only_text.lower().split()\n",
    "    words=[\" \".join(words.split()) for words in words]  \n",
    "    return \" \".join(words)\n",
    "\n",
    "# keep only words from the str\n",
    "keywords = preprocess(stringkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>election</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>voting</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>georgia</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>biden</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>law</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>democrats</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>texas</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>court</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>state</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>voter</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>voters</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ballots</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mail</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>senate</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vote</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>black</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>states</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword  freq\n",
       "0    election   216\n",
       "1      voting   170\n",
       "2       trump   159\n",
       "3     georgia   158\n",
       "4        bill   157\n",
       "5       biden   150\n",
       "6         law   134\n",
       "7   democrats   134\n",
       "8       texas   123\n",
       "9       court   122\n",
       "10      state   122\n",
       "11      voter   109\n",
       "12     voters   109\n",
       "13    ballots   103\n",
       "14       mail    91\n",
       "15         id    88\n",
       "16     senate    80\n",
       "17       vote    76\n",
       "18      black    75\n",
       "19     states    75"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Finding top keywords in overall corpus\n",
    "cnt_df_right = (pd.DataFrame(Counter(keywords.split()).most_common(20))) #another way of finding most common words in corpus\n",
    "cnt_df_right.columns=['keyword', 'freq']\n",
    "cnt_df_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>freq</th>\n",
       "      <th>left</th>\n",
       "      <th>freq</th>\n",
       "      <th>right</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voting</td>\n",
       "      <td>864</td>\n",
       "      <td>voting</td>\n",
       "      <td>698</td>\n",
       "      <td>election</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>election</td>\n",
       "      <td>604</td>\n",
       "      <td>trump</td>\n",
       "      <td>409</td>\n",
       "      <td>voting</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump</td>\n",
       "      <td>565</td>\n",
       "      <td>election</td>\n",
       "      <td>389</td>\n",
       "      <td>trump</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>483</td>\n",
       "      <td>state</td>\n",
       "      <td>370</td>\n",
       "      <td>georgia</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>court</td>\n",
       "      <td>445</td>\n",
       "      <td>court</td>\n",
       "      <td>320</td>\n",
       "      <td>bill</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law</td>\n",
       "      <td>395</td>\n",
       "      <td>rights</td>\n",
       "      <td>318</td>\n",
       "      <td>biden</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rights</td>\n",
       "      <td>368</td>\n",
       "      <td>law</td>\n",
       "      <td>278</td>\n",
       "      <td>law</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>voter</td>\n",
       "      <td>362</td>\n",
       "      <td>voters</td>\n",
       "      <td>255</td>\n",
       "      <td>democrats</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>voters</td>\n",
       "      <td>352</td>\n",
       "      <td>texas</td>\n",
       "      <td>218</td>\n",
       "      <td>texas</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>texas</td>\n",
       "      <td>344</td>\n",
       "      <td>georgia</td>\n",
       "      <td>186</td>\n",
       "      <td>court</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>georgia</td>\n",
       "      <td>342</td>\n",
       "      <td>black</td>\n",
       "      <td>183</td>\n",
       "      <td>state</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bill</td>\n",
       "      <td>316</td>\n",
       "      <td>democrats</td>\n",
       "      <td>180</td>\n",
       "      <td>voter</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>democrats</td>\n",
       "      <td>304</td>\n",
       "      <td>fraud</td>\n",
       "      <td>178</td>\n",
       "      <td>voters</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>biden</td>\n",
       "      <td>297</td>\n",
       "      <td>vote</td>\n",
       "      <td>168</td>\n",
       "      <td>ballots</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>black</td>\n",
       "      <td>258</td>\n",
       "      <td>bill</td>\n",
       "      <td>156</td>\n",
       "      <td>mail</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vote</td>\n",
       "      <td>243</td>\n",
       "      <td>carolina</td>\n",
       "      <td>153</td>\n",
       "      <td>id</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id</td>\n",
       "      <td>241</td>\n",
       "      <td>republicans</td>\n",
       "      <td>153</td>\n",
       "      <td>senate</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fraud</td>\n",
       "      <td>239</td>\n",
       "      <td>republican</td>\n",
       "      <td>153</td>\n",
       "      <td>vote</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ballots</td>\n",
       "      <td>228</td>\n",
       "      <td>id</td>\n",
       "      <td>150</td>\n",
       "      <td>black</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mail</td>\n",
       "      <td>219</td>\n",
       "      <td>north</td>\n",
       "      <td>150</td>\n",
       "      <td>states</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           df  freq         left  freq      right  freq\n",
       "0      voting   864       voting   698   election   216\n",
       "1    election   604        trump   409     voting   170\n",
       "2       trump   565     election   389      trump   159\n",
       "3       state   483        state   370    georgia   158\n",
       "4       court   445        court   320       bill   157\n",
       "5         law   395       rights   318      biden   150\n",
       "6      rights   368          law   278        law   134\n",
       "7       voter   362       voters   255  democrats   134\n",
       "8      voters   352        texas   218      texas   123\n",
       "9       texas   344      georgia   186      court   122\n",
       "10    georgia   342        black   183      state   122\n",
       "11       bill   316    democrats   180      voter   109\n",
       "12  democrats   304        fraud   178     voters   109\n",
       "13      biden   297         vote   168    ballots   103\n",
       "14      black   258         bill   156       mail    91\n",
       "15       vote   243     carolina   153         id    88\n",
       "16         id   241  republicans   153     senate    80\n",
       "17      fraud   239   republican   153       vote    76\n",
       "18    ballots   228           id   150      black    75\n",
       "19       mail   219        north   150     states    75"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge cnt_df, cnt_df_left, cnt_df_right\n",
    "cnt_df_right.columns=['right', 'freq']\n",
    "cnt_df_left.columns=['left', 'freq']\n",
    "cnt_df.columns=['df', 'freq']\n",
    "results = pd.concat([cnt_df, cnt_df_left, cnt_df_right], axis=1)\n",
    "results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98a3d57d6555b287d57a6e94fda6c04b60c6fddf99ca785e6b35ed0d66da8c0f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
